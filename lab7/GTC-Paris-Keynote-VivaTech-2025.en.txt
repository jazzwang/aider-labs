This is how intelligence is made. A new kind of factory. Generator of tokens The building blocks of AI Tokens have opened a new frontier The first step into an extraordinary world. Where endless possibilities are born. Tokens transform images into scientific data. Charting alien atmospheres. And guiding the explorers of tomorrow. They probe the Earth's depths. To seek out hidden danger. They turn potential Into plenty And help us harvest our bounty. Tokens see disease before it takes hold. Cure with precision And learn What makes us tick? Token connect the dots So we can protect our most noble creatures. Tokens decode the laws of physics. To move us faster. And make our days more efficient. Tokens don't just teach robots how to move,  but to bring joy. And comfort Mar. Hi. Are you ready to see the Dr.? What's that? It's my enchanting tool. Tokens help us move forward. One small step for man. Becomes one giant leap for mankind. So we can boldly go Where no one has gone before. And here Is where it all begins. Welcome to the Stage NVIDIA  Founder and CEO Jensen Huang. Oh. Bonjour. NVIDIA's first GTC in Paris. This is incredible. Thank you for all the  partners who are here with us. We have so many people that  we work with over the years. In fact, we've been in Europe for a very  long time though. This is my first GTC  Paris. I have a lot to tell you. NVIDIA, once upon a time,  wanted to create a new computing platform. To do things that normal computers cannot. We accelerated the CPU, created a new type of  computing called accelerated computing, and one  of our first applications was molecular dynamics. We've come a long way since. So many different libraries. And in fact,  what makes accelerated computing special? It's not just a new processor  that you compile software to. You have to reformulate how you do computing.  You have to reformulate your algorithm and it  turns out to be incredibly hard for  people to reformulate software and  algorithms to be highly parallelized. And so we created libraries to help. Each market, each domain of application. Becomes accelerated. Each one of these  libraries opens up new opportunities for the  developers and it opens up new opportunities  for growth for us and our ecosystem partners. Computational lithography. Probably the single  most important application in semiconductor  design today, runs in a factory at TSMC. Samsung large semiconductor fabs. Before the  chip is made, it runs through an inverse physics  algorithm called cuLitho, computational lithography. Direct sparse solvers Algebraic multi-grid solvers. CuOpt, we just opened sourced.  incredibly exciting Application Library.  This library accelerates decision making To optimize problems with millions of  variables for millions of constraints  like traveling salespeople problems. Warp, a Pythonic Framework for expressing  geometry and physics solversâ€¦really important. cuDF cuML, Structured databases, DataFrames,  classical machine learning algorithms cuDf accelerates Spark with zero  lines of code change. cuML accelerates Sidekick  learn with zero lines of code change. Dynamo and CuDNN cuDNN is probably the single most important  library NVIDIA has ever created. It accelerates  the primitives of deep neural networks. And  Dynamo is our brand new library that makes  it possible to dispatch, orchestrate,  distribute extremely complex inference  workloads across an entire AI factory. cuEquivariance and cuTensor tensor  contraction algorithms. Equivariance is for neural  networks that obey the laws of geometry, such as  proteins, molecules, Aerial, and Sionna. Really  important framework to enable AI to run 6G. Earth-2, our simulation environment for  foundation models of weather and climate models. Kilometer-squared, incredibly high resolution. MONAI, our framework for medical imaging,  incredibly popular. Parabricks is a solver  for genomics analysis incredibly successful. cuQuantum, CUDA-Q I'll talk about in just  a second for quantum computing and cuPyNumeric acceleration for NumPy and  SciPy. As you can see, these are just a few of  the examples of libraries. There are 400 others. Each one of them accelerates  a domain of application. Each one of them opens up new opportunities. Well, one of the most exciting. Most exciting is CUDA-Q. CUDA-X is this suite of libraries. Library suite for accelerating applications and  algorithms on top of CUDA. We now have CUDA-Q. CUDA-Q is for quantum computing. For  quantum classical computing based on GPUs. We've been working on CUDA now for several years. And today I can tell you there's an inflection  point happening in quantum computing. As you know. The first physical qubit was  demonstrated some nearly 30 years ago. An error correction algorithm  was invented in 1995. And in 2023, almost 30 years later. The world's first logical  qubit was demonstrated by Google. Since then, a couple of years later, the number  of logical qubits which is represented by a whole  lot of physical qubits with error correction,  the number of logical qubits are starting to grow. Well, just like Moore's Law would. I could totally  expect ten times more logical qubits every  five years, 100 times more logical qubits  every ten years. Those logical qubits would  become better error corrected, more robust,  higher performance, more resilient, and  of course will continue to be scalable. Quantum computing is reaching an inflection  point. We've been working with quantum  computing companies all over the  world in several different ways,  but here in Europe there's a large community. I saw Pascal last night. I saw Barcelona  supercomputing last night. It is clear now. We are within reach of being able to apply  quantum computing, quantum classical  computing, in areas that can solve some  interesting problems in the coming years. This is a really exciting time. and  so we've been working with all of the  supercomputing centers. It's very clear now. That over the next several years, or at  least the next generation of supercomputers,  every single one of them will have a QPU  assigned and QPU connected to GPUs. The QPU  will do quantum computing, of course. And the GPUs would be used for  pre processing for control. Error correction, which would  be intensely computationally intensive,  post processing and such. Between the two  architectures, just as we accelerated the  CPU, now there's QPU working with the GPU  to enable the next generation of computing. Well, today we're announcing that our entire  quantum algorithm stack is now accelerated on  Grace Blackwell 200 and the speed up is utterly  incredible. We work with the Quantum computing  industry in several different ways. One way is  using cuQuantum to simulate the qubits or simulate  the algorithms that runs on top of these quantum  computers, essentially using a classical computer  to simulate or emulate a quantum computer. At the other extreme,  extremely important is CUDA-Q. Basically inventing a new CUDA that  extends CUDA into quantum classical so  that applications that are developed on CUDA. Can run before the quantum computer arrives  in an emulated way or after the quantum  computer arrives in a collaborative way. A quantum classical  accelerated computing approach. And so today we're announcing CUDA  is available for Grace Blackwell.  The ecosystem here is incredibly rich. Of course, Europe is deep with science  and deep with supercomputing  expertise and deep with heritage  in this area. And it's not surprising to see. quantum computing advance here. in the next  several years, we're going to see a really  fantastic inflection point. So anyways, for  all of the quantum industry that have been working  on this for three decades now, I congratulate you  for just the incredible accomplishment  and the milestones today. Thank you. Let's talk about AI. You might be surprised That I would I would be talking to  you about AI. the same, the same GPU. That Ran and enabled all of these  applications that I mentioned. That same GPU. Enabled artificial intelligence to come  to the world. Our first contact  was in 2012 just prior to that. Working with developers on a new  type algorithm called deep learning. It enabled the AlexNet big bang of AI in 2012. In the last 15 years or so AI has progressed  incredibly fast. The first  wave of AI was perception. For computers to recognize information. Understand it. The second wave,  which most of us were talking about. The last five years or so was Generative AI.  It's multimodal, meaning that an AI was  able to learn both images and Language. Therefore, you could prompt with  Language and it could generate images. The ability of AI to be multimodal as  well as able to translate and generate  content enabled the Generative AI revolution. Generative AI, the ability to generate content  is fundamentally vital. For us to be productive Well, we've got a new, we are starting a new  wave of AI. and this last couple of years  we've seen enormous progress in AI's ability. Fundamentally, intelligence  is about understanding. Perception Reasoning Planning a task, how to solve a problem, and  then executing the task, perception, reasoning,  planning. the fundamental cycles of intelligence.  It allows us to apply some previously learned  rules to solve problems we've never seen before. That's why intelligent people are considered  intelligent to be able to take a complicated  problem, break it down step by step. Reason about how to solve the  problem, maybe do research. Maybe go learn some new information. Get some help, use tools, and solve  problems step by step. Well, the words  that I just described are fundamentally  possible today with what is called Agentic  AI, and I'll show you more in just a second. In the physical implementation of that,  the embodiment of that Agentic AI. Now the Generative capability is generating  motion. Instead of generating videos and  generating images or generating text, this AI  generates locomotion, the ability to walk or  reach out and grab something, use tools. The ability for AI to be embodied in  a physical form is basically robotics. These capabilities. the fundamental technology To enable agents, which are basically information  robots and embodied AI, physical robots. These two  fundamental capabilities are now upon us. really,  really exciting times for AI. But it all started. It all started with GeForce. And GeForce brought computer  graphics. This is the first accelerated  computing application we had ever worked on. And it's incredible how far  computer graphics has come. GeForce brought CUDA to the world, which  enabled machine learning researchers and  AI researchers to advance deep learning. Then deep learning revolutionized computer  graphics and made it possible for us to  bring computer graphics to a whole new level. Everything I'm going to show you today. Everything I'm going to you today,  I'm going to give you a preview of what I'm going  to show you. But everything I'm going to show you  today is computer simulation, not animation. It's photon simulation, physics simulation,  particle simulations. Everything is fundamentally  simulation, not animation, not art. It just  looks incredibly beautiful because it turns  out the world is beautiful and it turns out  math is beautiful. So let's take a look.What do you think? Numbers in action. Numbers in  action. That's essentially what simulations are  and it's just incredibly beautiful to look at.  But because of the scale. And the speed by which we  can now simulate almost everything. We can turn everything into a digital  twin. And because everything can be a digital  twin, it could be designed, planned, optimized,  and operated completely digitally before we  put it into the physical world. The idea that  we would build everything in software is now upon  us. Everything physical will be built digitally.  Everything that's built magnificently  will be built digitally. Everything  that's operated at gigantic scale will be first  built digitally, and there will be digital twins  that operate it. And so today we're going  to talk a lot about digital twins. Well,  what started out as a GeForce graphics  cardâ€¦Anybody in here know what a GeForce is? Okay. Right. Well, what started out as GeForce? Looks like this now this is the new GeForce. It is  two tons, two and a half tons, 1.2 million parts. About $3 million 120 KW. Manufactured in 150 factories. 200 technology partners  working with us to do this. Probably something along the lines of $40  billion in R&amp;D budget in order to create  what is GB200 and now moving to GB300. It is  completely in production. And this machine was  designed to be a thinking machine. A thinking  machine in the sense that it reasons, it plans. It spends a lot of time talking to itself. Just like you do. We spend most of our time generating words for  our own mind, generating images for our own mind  before we produce it. And so the thinking machine  is really architecturally what Grace Blackwell was  designed to do. It was designed to be one giant  GPU. I compared it to GeForce for a good reason. GeForce is one GPU, so is GB200. It is one giant  virtual GPU. Now we had to disaggregate it into  a whole bunch of components, create a bunch of  new networking technology and SerDes technology,  incredibly low, low power, high energy efficiency  interconnects to connect all of these chips and Systems together into one virtual  GPU. This is the hopper version.  This is the world famous hopper system. Eight GPUs connected together on NVLink. What's not shown here is a CPU  tray, a CPU tray with dual CPU  and system memory that sits on top together. This represents one node of an AI supercomputer About half a million dollars. This is  the hopper system. This is the system  that really put us on the map of AI and It  was under allocation for a very long time. Because the market took off so quickly. But this  is the famous Hopper system. Well, this entire  system, including the CPU, is replaced by this. Great Blackwell node. This is one compute tray. Right here we'll replace that entire  system. It is fully liquid cooled. And the CPUs are integrated directly  connected to the GPUs. So you could  see it here, two CPUs, four GPUs it is  more performant than that entire system. But what's amazing is this: we wanted to connect  a whole bunch of these systems together. How would  you connect all of these together was really hard  for us to imagine. So we disaggregated it. What we  did was we took that entire motherboard.  We disaggregated into this and this. This is the revolutionary NVLink system. Scaling out computing is not that hard.  Just connect more CPUs with Ethernet. Scaling  out is not hard. Scaling up is incredibly hard. You can only build as large of  a computer as you can build. The amount of technology and electronics that  you could fit into one memory Model is incredibly  hard to do. And so what we decided to do was we  create a new interconnect called NVLink. NVLink  is a memory semantics interconnect.  It's a compute fabric, not a network. It directly connects to the CPU of  all of these different NVLink systems  compute nodes. This is the switch. Nine of these stand on top. Nine of  it sits on the bottom. In the middle are  the NVLink switches and what connects it  together is this miracle. This is the NVLink spine. This is 100% copper. Copper coax. It directly  connects all of the NVLink chips to all  of the GPUs directly connected over. This entire spine so that every single one of  the 144 Blackwell dies in 72 different packages  are talking to each other at the same time. Without blocking all across this NVLink spine,  the bandwidth of this is about  130 terabytes per second. 130. I know. No, wait for it. wait for it. 130 TBps if it's in bits. 130 TBps It is more than the data rate of the  peak traffic of the world's entire  internet traffic, on this backplane. Yeah. So this is how you shrink the internet into  60 pounds. NVLink And so we did all that. We did all that  because the way you think about computers  is going to be fundamentally different in the  future and I'll spend more time on this but  it was designed to give Blackwell a giant leap  above hopper. Remember Moore's Law semiconductor  physics is only giving you about two times  more performance every three to five years. How could we achieve 30, 40 times more  performance in just one generation? And  we need a 30, 40 times more performance because  the reasoning models are talking to themselves. Instead of one-shot ChatGPT, it's now a reasoning  model and it generates a ton more tokens. When  you're thinking to yourself, you're breaking  the problem down step by step. You're reasoning,  you're trying a whole bunch of different  paths. Maybe it's chain of thoughts,  maybe it's tree of thoughts. Best of end, it's  reflecting on its own answers. You've probably  seen these research models reflecting on the  answer, saying, is this a good answer? Can you do  better than that? And they the, oh yeah, I can do  better than that goes back and thinks some more.  And so those thinking models, reasoning models  achieve Incredible performance, but it requires  a lot more computational capability. And the net  result? NVLink 72 with Blackwellâ€™s architecture  resulted in a giant leap in performance. The way to read this is the x axis is how fast  it's thinking. The y axis is how much the factory  can output supporting a whole bunch of users at  one time. And so you want the throughput of the  factory to be as high as possible so you could  support as many people as possible so that the  revenues of your factory is as high as possible. You want this axis to be as large as possible  because the AI is smarter here than it is here.  The faster it can think, the more it can think  before it answers your question. And so this  has to do with the ASP of the average selling  price of the tokens and this has to do with the  throughput of the factories. These two combined  in that corner is the revenues of the factory. This factory based on Blackwell can generate a  ton more revenues as a result of the architecture. It is such an incredible thing what we built. We made a movie for you just to give you a  sense of the enormity of the engineering  that went into building Grace Blackwell,  take a look. video Blackwell is an engineering marvel. It begins as a blank silicon wafer. Hundreds of chip processing  and ultraviolet lithography  steps build up each of the two hundred billion  transistors layer by layer on a twelve -wafer. The wafer is scribed into individual  Blackwell dies, tested and sorted,  separating the good dies to move forward. The chip on wafer on substrate process  attaches 32 Blackwell dies and 128 HBM  stacks on a custom silicon interposer wafer. Metal interconnect traces are etched directly  into it, connecting Blackwell GPUs and HBM  stacks into each system and package  unit, locking everything into place. Then the assembly is baked, molded,  and cured, creating the Blackwell  B200 superchip. Each Blackwell  is stress-tested in ovens at 125 Â°C. And pushed to its limits for several hours. Robots work around the clock  to pick and place over 10,000  components onto the Grace Blackwell PCB. Meanwhile, custom liquid cooling copper  blocks are prepared to keep the  chips at optimal temperatures. At another facility, ConnectX-7 super NICs are  built to enable scale-out communications and  BlueField-3 DPUs to offload and accelerate  networking, storage, and security tasks. All these parts converge to be carefully  integrated into GB200 compute trays. NVLink is the breakthrough high speed link  that NVIDIA invented to connect multiple  GPUs and scale up into a massive virtual GPU. The NVLink switch tray is constructed with NVLink  switch chips providing 14.4 TBps of all-to-all  bandwidth. NVLink spines form a custom blind mated  backplane with 5,000 copper cables connecting all  72 Blackwells or 144 GPU dies into one giant GPU  delivering 130 TBps of all-to-all bandwidth,  more than the global internet's peak traffic. From around the world, parts arrive to  be assembled by skilled technicians into  a rack-scale AI supercomputer. In total 1.2 million components,  2 miles of copper cable, 130 trillion  transistors, weighing nearly two tons. Blackwell is more than a technological  wonder. It's a testament to the power  of global collaboration and innovation,  fueling the discoveries and solutions  that will shape our future everywhere. We are driven to enable the geniuses of  our time to do their lifeâ€™s work and we can't  wait to see the breakthroughs you deliver.Grace Blackwell Systems All in production. It is really a miracle.  It's a miracle from a technology perspective.  But the supply chain that came together to build  these GB200 systems, two tons each, we're  producing them now, 1,000 systems a week. No one has ever produced mass produced  supercomputers at this scale before. Each one of these racks is essentially  an entire supercomputer. Only in 2018,  the largest Volta system, the Sierra supercomputer  in 2018 is less performant than one of these racks  and that system was 10 MW. This is 100 KW. So the  difference generationally between 2018 and now,  we've really taken supercomputing,  AI supercomputing to a whole new  level and we're now producing these machinery at  enormous scales. And this is just the beginning. In fact, what you've seen is just one system,  Grace Blackwell. The entire world is talking  of this one system, clamoring for it to get  deployed into the world's data centers for  training and inferencing and Generative AI.However, not everybody and not every data  center handle these liquid cooled systems.  Some data centers require enterprise stacks,  the ability to run Linux, Red Hat, or or VMware.  Storage systems from Dell, Emc, Hitachi, Netapp,  Vast, Weka, so many different storage systems,  so many different IT systems. And the management  of those has to be done in a way that's consistent  with traditional IT systems. We have so many new  computers to ramp into production and I'm so happy  to tell you that every single one of these are  now in production. You haven't seen them yet.  They're all flying off the shelves, flying off  the ramps, the manufacturing lines starting here. DGX Spark enables you to have essentially  the Grace Blackwell system on your desktop  in the case of Spark desktop, in the case of DGX  station desk side. This way you don't have to sit  on a supercomputer while you're developing your  software, while you're developing your AI, but  you want the architecture to be exactly the same. These systems are identical from an architecture  perspective. From a software developer  perspective, it looks exactly the same.  The only difference is scale and speed.  And then on this side are all the X86  systems. The world's IT organizations still  prefer X86 and appreciate X86 wherever they  can take advantage of the most advanced AI  native systems. They do where they can't  and they want to integrate into the enterprise IT  systems, we now offer them the ability to do so. One of the most important systems and it has  taken us the longest to build because of the  software and the architecture is  so complicated is how to bring. The AI native architecture and infuse it  into the traditional enterprise IT system. This is our brand new RTX Pro  server. This is an incredible system. The motherboard is completely redesigned. Ladies and gentlemen, Janine Paul. This motherboard looks so simple. And yet on top of this motherboard  are eight super NIC switches that connect eight  GPUs across a 200 Gbps state of the art networking  chip that then connects eight of these GPUs and  these Blackwell RTX Pro 6000 GPUs, brand new,  just entered into production. Eight of these go into a  server. Now what makes it special? This server is the only server in  the world that runs everything the world has ever  written and everything NVIDIA has ever developed. It runs AI, Omniverse, RTX for video  games. It runs Windows, it runs Linux,  runs Kubernetes, it runs Kubernetes and VMware. It runs basically everything. If you want to  stream Windows desktop from a computer to your  to your remote device, no problem. If you want  to stream Omniverse, no problem. If you want  to run your robotics stack, no problem. Just  the QA of this particular machine is insane. The  applications that it runs are basically universal.  Everything the world's ever developed should  run on here, including If you're a video gamer,  including crisis. And so if you can  run crisis, you can run anything. Okay, this is the RTX Pro Server  brand new enterprise system. So something is changing. We know that AI is incredibly  important technology. We know for a fact now that AI is software that  could revolutionize, transform every industry. It can do these amazing things. That we know We also know that the way you  process AI is fundamentally  different than the way we used to  process software written by hand. Machine learning software is developed  differently and it runs differently. The architecture of the systems, the architecture  of the software are completely different. The way  the networking works is completely different.  The way it acts is completely different. So we know that the technology can do  different things, incredible things. It's intelligent. We also know that  it's developed in a fundamentally  different way and needs new computers. The thing that's really interesting,  is what does this all mean, to  countries, to companies, to society. And this, this is an observation that  we made almost a decade ago that now  everyone is awakening to, that in fact these  AI data centers are not data centers at all. They're not data centers in  the classical sense of a data  center storing your files that you retrieve. These data centers are not storing our files.  It has one job and one job only: to produce  intelligent tokens, the generation of AI. These factories of AI look like  data centers in the sense that  they have a lot of computers inside. But that's where everything breaks down. How it's designed, the scale at  which its manufactured or scaled,  designed and built and how it's used. And how it's orchestrated and  provisioned, operated. How you think about it? For example, nobody really thinks about their  data center as a revenue generating facility. I said something that everybody  goes, yeah, I think you're right. Nobody ever thinks about a data center as a  revenue-generating facility, but they think  of their factories, their car factories, as  revenue-generating facilities. And they can't  wait to build another factory because whenever  you build a factory, revenue grows shortly  after you could build more things for more people. Those ideas are exactly the same ideas in these AI  factories. They are revenue-generating facilities  and they are designed to manufacture tokens. And these tokens can be reformulated into  productive intelligence for so many industries  that AI factories are now part of a country's  infrastructure which is the reason why you see  me running around the world talking to heads of  state, because they all want to have AI factories.  They all want AI to be part of their  infrastructure. They want AI to be a  growth manufacturing industry for them. And this is genuinely profound. And I think we're talking about,  as a result of all that, a new  industrial revolution because every single  industry is affected, and a new industry. Just as electricity became a new industry. At first when it was described as a  technology and demonstrated as a technology. It was understood as a technology, but then we  understood that it's also a large industry. Then there's the information in industry. Which we now know as the internet. And both of  them, because it affected so many industries,  became part of infrastructure.  We now have a new industry. An AI industry and it's now part of the  new infrastructure called intelligence  infrastructure. Every country, every society,  every company will depend on it. And you could  see its scale. This is one that's being talked  about a lot. This is Stargate. This doesn't look  like a data center. It looks like a factory. This  is 1 GW. It will hold about 500,000 GPU dies. And produce an enormous amount of  intelligence that could be used by everybody. Well, Europe has now awakened to the  importance of these AI factories,  the importance of the AI infrastructure, and  I'm so delighted to see so much activity here. This is European telcos building  AI infrastructure with NVIDIA. This is the European cloud service providers  building AI infrastructure with NVIDIA. And this is the European Supercomputing  centers, building next generation AI  supercomputers and infrastructure with NVIDIA.  And this is just the beginning. This is. In addition to what will come in the  public clouds. This is in addition to  the public clouds. So indigenous-built AI  infrastructure here in Europe by European  companies for the European market. And then there's 20 more being planned. 20 more AI factories and several  that are gigawatt factories. In total in just two years we will  increase the amount of AI computing  capacity in Europe by a factor of ten. And so the researchers, the startups:  your AI shortage, your GPU shortage will be  resolved for you soon. It's coming for you. Now we're partnering with each country to  develop their ecosystem. And so we're building AI  technology centers in seven different countries. And the goal of these AI technology centers  is one, to do collaborative research To work with the startups and also to build  the ecosystem. Let me show you what an ecosystem  looks like in the Uk. I was just there yesterday. The ecosystems are built on top of  the NVIDIA stack. So for example. Every single NVIDIA. As you know,  NVIDIA is the only AI architecture  that's available in every cloud. It's the only computing architecture  aside from X86 that's available everywhere. We partner with every cloud service provider. We accelerate applications from the most important  software developers and in the world, Siemens  here in Europe, Cadence, Red Hat, Servicenow. We've reinvented the computing stack. As you know,  computing is not just a computer, but  it's compute, networking, and storage.  Each one of those layers, each one of those stacks  has been reinvented. Great partnership with Cisco,  who announced a brand new model yesterday  at their conference based on NVIDIA. Dell.  Great partnerships. Netapp. Nuts. A  whole bunch of great partnerships. As I mentioned earlier, the way you develop  software has been fundamentally changed. It's no longer just write C programs,  compile C programs, deliver C programs. It's now Devops, MLOps, AI Ops. So that  entire ecosystem is being reinvented and  we have ecosystem partners everywhere  and then of course solution integrators  and providers who could then help every  company integrate these capabilities. Well, here in the UK we have special companies  that we work with, really terrific companies  from researchers to developers, to partners to  help us upskill the local economy and upskill  the local talent, enterprises that consume the  technology, and of course cloud service providers. We have great partners in the UK,  We have great partners in Germany. Incredible, incredible partnerships in Germany. We  have partnerships in Italy, and we of course have  amazing partnerships here in France. That's right, go France. President Macron is going to be here later on.  We're going to talk about some new announcements.  So we have to show some enthusiasm for AI. Okay. Yeah. There you go. Show  him some enthusiasm. So great partnerships. Here in France, one particular one I want to  highlight is our partnership with Schneider.  Building, even building these AI factories,  we build them digitally now. We design them  digitally, we build them digitally, we operate  them or optimize them digitally, and we will  even eventually optimize them and operate  them completely digitally in a digital twin. AI factories are so expensive. $50 billion sometimes. $100 billion in the future. If the utilization of that factory is  not at its fullest, the cost to the factory  owner is going to be incredible. And so we  need to digitalize and use AI wherever we can.  Put everything into Omniverse so that we have  direct and constant telemetry. We have a great  partnership here that we're announcing today. Young company , a CEO. I really like, and  he's trying to build a European AI company. The name of the company is Mistral. Today  we're announcing that we're going to build  an in AI cloud together here to deliver their  models as well as deliver AI applications for  the ecosystem of other AI startups so  that they can use the Mistral models,  or any model that they like. And so with Mistral  we are going to be partnering to build a very  sizable AI cloud here. And we'll, we'll talk about  more of it later on today with President Macron. AI technology is moving at light speed. And what I'm showing you here, proprietary  models on the left moving at light speed. However, the open models are also moving  at light speed, only a few months behind. Whether it's Mistral, Llama, DeepSeek R1,  R2 coming, Qwen. These models are all exceptional. Every single one of them is exceptional. And  so we've dedicated ourselves over the  last several years to apply some of the  world's best AI researchers to make those AI  models even better and we call that Nemotron. Basically, what we do is we take the models  that are open-sourced, and of course they're  all built on NVIDIA anyhow, and we take those  open-sourced models, we then post-train it. We might do neural architecture search.  We might do neural architecture search,  provided with even better data. Use reinforcement learning techniques, enhance  those models, give it reasoning capabilities. Extend the context so that it could learn and  read more before it interacts with you. Most of these models have relatively  short context, and we wanted to have enormous  context capability because we want to use it in  enterprise applications where the conversation  we want to have with it is not available on the  internet. It's available in our company, and so  we have to load it up with an enormous amount  of context. All of that capability is then  packaged together into a downloadable NIM.  You could come to NVIDIA's website and literally  download an API, a state of the art AI model. Put it anywhere you like and  we improve it tremendously. This is an example of Nemotron improvement over  Llama. So Llama 8B, 70B, 405B improved by our  post-training capability, extension of reasoning  capability, all the data that we provide. We  enhanced it tremendously. We're going to do this  generation after generation after generation. And  so for all of you who use Nemotron, you will  know that there's a whole slew of other models  in the future, and they're open anyway, so if  you would like to start from the open model,  that's terrific. If you'd like to start with  the Nemotron model, that's terrific. And the  Nemotron models, the performance is excellent.  In benchmarks after benchmarks after benchmarks,  Nemotron performance has top of the leaderboard  all over the place. And so now you know that you  have access to an enhanced open model that is  still open, that is top of the leader charts. And you know that NVIDIA is dedicated  to this. And so I will do this for  as long as I shall live. Okay. This strategy is so good. This  strategy is so good that the regional model  makers, the model builders across Europe,  have now recognized how wonderful the strategy is  and we're partnering together to adapt, enhance  each one of those models for regional languages. Your data belongs to you. Your data belongs  to you. It is the history of your  people, the knowledge of your people,  the culture of your people. It belongs to you. And for many companies, in the case of NVIDIA,  our data is largely inside. 33 years of data. I was looking up this morning Siemens 180 years of  data. Some of it written down on papyrus. Roland  Bush is here. I thought I'd pick on Roland Bush,  my good friend. And so you'll have to  digitize that before the AI can learn. And so the data belongs to you. You should use  that data. Use an open model like Nemotron and  all the tool suites that we provide so  that you can enhance it for your own use. We're also announcing that we have a great  partnership with Perplexity. Perplexity as a  reasoning search engine. Yep.  The three models I use, I use ChatGPT, Gemini Pro,  and Perplexity, and these three models are used  interchangeably. And Perplexity is fantastic. We're announcing today that Perplexity will  take these regional models and connect it  right into Perplexity so that you could now  ask and get questions in the language, in the  culture and the sensibility of your country. Okay, so Perplexity regional models. Agentic AI. Agentic AI. Agents is a very big deal. You know, in the beginning with pre-trained  models, people said, but it hallucinates. It  makes things up. You're absolutely right. It doesn't have access to the latest news  and data information. Absolutely right. It gives up without reasoning through problems.  It's as if every single answer has to be memorized  from the past. You're absolutely right. All of those things, you know, why is it  trying to figure out how to add or count the  count numbers and add numbers? Why doesn't  it use a calculator? You're absolutely right. And so all of those capabilities associated with  intelligence, everybody was able to criticize,  but it was absolutely right because everybody  largely understands how intelligence works. But those technologies were being built all around  the world and they were all coming together, from  retrieval augmented generation, to web search,  to multimodal understanding so that you can read  PDFs, go to a website, look at the images and the  words, listen to the videos, watch the videos. And then take all of that understanding into  your context. You could also now understand,  of course, a prompt from almost anything. You could even say, I'm going to ask you  a question, but start from this image. I  could say start from this text. Before you answer the question  or do what I ask you to do. It then goes off and reasons  and plans and evaluates itself. All of those capabilities are now  integrated and you can see it coming out into  the marketplace all over the place. Agentic AI  is real. Agentic AI is a giant step function  from one-shot AI. One-shot AI was necessary to  lay the foundation so that we can teach the  agents how to be agents. You need some basic  understanding of knowledge and basic understanding  of reasoning to even be able to be teachable. And  so pre-training is about the teachability of AI. Post-training reinforcement learning, supervised  learning, human demonstration,  context provision, generative AI. All of that is coming together to  formulate what is now Agentic AI. Let's take a look at one example. Let me show  you something. It's built on Perplexity and  it's super cool. video AI agents are digital assistants. Based on  a prompt, they reason through and break down  problems into multi-step plans. They use  the proper tools, work with other agents,  and use context from memory to properly execute  the job on NVIDIA accelerated systems. It starts  with a simple prompt. Let's ask Perplexity  to help start a food truck in Paris. First,  the perplexity agent reasons through the  prompt and forms a plan. Then calls other  agents to help tackle each step using  many tools. The market researcher reads  reviews and reports to uncover trends  and analyze the competitive market.  Based on this research, a concept designer  explores local ingredients and proposes a menu  complete with prep time estimates. It researches  palettes and generates a brand identity. Then the  financial planner uses Monte Carlo simulations to  forecast profitability and growth trajectory. An  operations planner builds a launch timeline with  every detail, from buying equipment to acquiring  the right permits. The marketing specialist  builds a launch plan with a social media  campaign,and even codes an interactive website  including a map, menu, and online ordering. Each  agent's work comes together in a final package  proposal, and it all started from a single prompt.One prompt, one prompt like that in the original  chatbot would have generated a few hundred tokens,  but now with that one single prompt  into an agent to solve a problem,  it must have generated 10,000 times more tokens. This is the reason why Grace Blackwell is  necessary. This is the reason why we need  performance and the systems to be so much  more performant generationally. Well, this is how  Perplexity builds their agents. Every company will  have to build their own agents. It's is terrific,  you're going to be hiring agents from OpenAI and Gemini and Microsoft CoPilot and  Perplexity and Mistral and they'll  be agents that are built for you. And they might help you plan a vacation or  you know, go do some research, so on, so forth. However, if you want to build a company, you're  going to need specialized agents with specialized  tools and using specialized tools and specialized  skills. And so the question is, how do you build  those agents? And so we created a platform for  you. We created a framework, and a set of tools  that you can use and a whole bunch of partners  to help you do it. It starts with on the very  bottom, on the very bottom, the ability to have  reasoning models that I spoke about. NVIDIAâ€™s Nemotron reasoning Large  Language models are world-class. We have NeMo Retriever, which is  a multimodal search engine, semantic search  engine, incredible. And we built a blueprint,  a demonstration that is operational, that is  essentially a general agent. We call it AI-Q. And on top we have a suite of tools  that allows you to onboard an agent,  a general agent, curate data to teach it,  evaluate it, guardrail it, supervised train it,  use reinforcement learning all the way to  deployment, keep it secure, keep it safe. That suite of toolkits is integrated, those  libraries are integrated, into the AI ops  ecosystem. You can come and download it from  our website yourself as well, but it's largely  integrated into AI ops ecosystem. From that,  you could create your own special agents. Many companies are doing this. This is Cisco.  They announced it yesterday. We're building AI  platforms together for security. Now look at this. AI agents, and not one model that does all of  these amazing things, are a collection or a  system of models. It's a system of large  language models. Some of them are optimized  for certain types of things. Retrieval, as I  mentioned, performing skills, using a computer. You don't want to bundle all of that stuff up  into one giant mass of AI, but you break it up  into small things that you could then deploy CICD  over time. This is an example of Cisco's. Now the  question is how do you now deploy this? Because as I mentioned earlier,  there are public clouds where NVIDIAâ€™s  compute is, there are regional clouds,  we call them NCPs here, for example Mistral. You might have something that is a private cloud,  because of your security requirements  and your data privacy requirements. You might even decide that you  have something on your desk. And so the question is, how do you run all of  these, and sometimes theyâ€™re running in different  places because these are all microservices. These are AIs that could talk to each other,  they could obviously talk to each other over  networking. And so how do you deploy all of  these microservices? Well, we now have a great  system. I'm so happy to announce this for you. This is called our DGX Lepton. DGX  Lepton. What you're looking at here  is a whole bunch of different clouds. Here's  the Lambda cloud, the AWS cloud, you know,  here's your own developerâ€™s machine. Your  own system could be a DGX station. Nebius,  Yoda, and Scale. It could be AWS, it could  be GCP. NVIDIAâ€™s architecture is everywhere. And so you could decide where you would like  to run your models. You deploy it using one  super cloud. So it's a cloud of clouds. Once  you get it to work, once you get these NIMs  deployed into Lepton, it will go and be hosted  and run on the various clouds that you decide.  One model architecture, one deployment and you  can run it everywhere. You can even run it on  this little tiny machine here. You know, this DGX Spark. Is it cafe time? Look at this This lift is 2000 horsepower. This is my favorite little machine.  DGX Spark, the firstâ€¦the AI supercomputer.  We built an AI supercomputer in 2016. It's  called the DGX-1. It was the first version.  everything that I've been talking about.  Eight Volta GPUs connected with NVLink. It took us billions of dollars to build.  And on the day we announced it, DGX-1, there  were customers, no interest, no applause. 100% confusion Why would somebody build a computer like that? Does it run windows? Nope. And so we built it anyway. Well,  thankfully, a young company, a startup, a  nonprofit startup in San Francisco was so  delighted to see the computer. They said, can we  have one? And I thought, oh my gosh, we sold one,  but then I discovered it was a non-profit. But I put a computer, put a DGX-1 in my car,  and I drove it up to San Francisco.  And the name of that company is OpenAI. I don't know what the life lesson is there.  There are a lot of non profits. You know,  so next time, next time maybe the lesson is this:  if a developer reaches out to you a needs a GPU,  the answer is yes. And so that's right. So imagine, you have Lepton. It's in your  browser and you have this this helm chart. An AI  agent that you've developed and you want to run  it here and parts of it you want to run in AWS and  parts of it you want to run you know in a regional  cloud somewhere. You use Lepton, you deploy  your helm chart, and it magically shows up here. Okay, and so if you would like to run it  here until you're done with it and ready  to deploy it and then deploy it into the  cloud, terrific. But the beautiful thing is  this architecture is based on Grace Blackwell  GB10 versus GB200, vs GB300, and all of these  different versions of this architecture is  exactly Grace Blackwell. Now this is amazing. So we're doing this for Lepton,  but, next, HuggingFace and NVIDIA  have connected Lepton together. And so whenever you're training  a model on HuggingFace, if you would like to  deploy it into Lepton and directly into Spark,  no problem. It's just one click. So  whether you're training or inferencing,  we are now connected to HuggingFace and Lepton  will help you decide where you want to deploy  it. Let's take a look at it. video Developers need easy and reliable access  to compute that keeps up with their work.  Wherever they are, whatever they're  building. DGX Cloud Lepton provides on  demand access to a global network of GPUs  across clouds, regions, and partners like  Yoda and Nebius. Multi cloud GPU clusters are  managed through a single unified interface.  Provisioning is fast. Developers can  scale up the number of nodes quickly  without complex setups and start training  right away with pre-integrated tools and  training-ready infrastructure. Progress is  monitored in real time. GPU performance,  convergence and throughput are at your fingertips.  You can test your fine-tuned models right within  the console. DGX cloud Lepton can deploy NIM  endpoints or your models in multiple clouds  or regions for fast distributed inference. Just  like ride-sharing apps connect riders to drivers,  DGX Cloud Lepton connects developers to GPU  compute, powering a virtual global AI factory.DGX cloud Lepton. Okay, so that's Cisco. This is the way SAP,  they're building an AI platform onNVIDIA. Sana  is building an AI business application automation  on NVIDIA. DeepL is building their language  framework and platform on NVIDIA. AI Photo Room,  a video editing and AI editing platform is  building their platform on NVIDIA. And this  is Qodo, I think used to be Qodium, incredible  coding agent built on NVIDIA. And this is Aiola,  a voice platform built on NVIDIA. And this one  is a clinical trial platform, the world's largest  automation platform for clinical trials,  built on NVIDIA. And so all of these,  all of these basically build on the same idea. NIMs that encapsulate and package up in a virtual  container that you could deploy anywhere,  the Nemotron large language model or other  large language models like Mistral or others. We then integrate libraries that basically covers  the entire lifecycle of an AI agent. The way you  treat an AI agent is a little bit like a digital  employee. So your IT department would have to  onboard them, fine-tune them, train them, evaluate  them, keep them guardrailed, keep them secure  and continuously improve them. And that entire  framework platform is called NeMo. And all of  that is now being integrated into one application  framework after another all over the world. This is just an example of a few of them. And then  now we make it possible for you to deploy them  anywhere. If you want to deploy it in the cloud,  you got DGX, you got GB200s in the cloud. If you  want to deploy it on-prem, because you've got  VMware or Red Hat Linux or Neutonix and you want  to deploy it in your virtual machines on-prem,  you can do that. If you wanted  to deploy it as a private cloud,  you could do that. You can deploy it all the way  on your DGX Spark or DGX Station. No problem. And so Lepton will help you do all of that. Let's talk about industrial AI. This is one of my favorite moments. This is Roland  Bush. He just, this is a really fun moment. He  wanted to remind me that neural computers, neural  network computers, were invented in Europe. That's this whole slide. I just, it was such a great moment. This is  Synapse1. This is incredible, you guys. Synapse1. This is Synapse1, 1992. It runs neural networks  8000 times faster than CPUs at that time. Isn't it incredible? So this  is the world's AI computer. And Roland just wants to just. Never forget that,  Jensen. Never, ever forget that. I said, okay,  all right, I'll tell and I'll even tell everybody. Siemens, 1992. Siemens, 1992. We have a great partnership with  Siemens and Roland Bush, the CEO, is supercharging  the company so that they could leap, completely  leap the last, IT industrial revolution and  fuse the industrial capabilities of Europe, the  industrial capabilities and might of Siemens with  artificial intelligence and create what is called  the industrial AI revolution. We're partnering  with Siemens on so many different fronts. Everything from design to simulation  to digital twins of factories,  to operations of the AI in the factories. Everything from end to end. And it just  reminds us, it reminds me how incredible  the industrial capabilities of Europe are. And what an extraordinary opportunity this is  for you. What an extraordinary opportunity.  Because AI is unlike software. AI is really smart  software. And this smart software can finally  do something that can revolutionize  the very industries that you serve. And so we made a love letter  video if you will. Let's play it. video It began here. The first industrial revolution. Wattsâ€™ steam engine and the mechanized loom. Introduced automation And the advent of factories. And industry was born The age of electricity. Ampere unraveled electromagnetism. Faraday built the first electric generator. And Maxwell laid the foundations For modern electrical engineering. Siemens and Wheatstoneâ€™s Dynamo. The engine of electricity. Bringing machine, trains,  factories and cities to life. Electrifying the planet. Igniting modern manufacturing And today, born out of the  computing and information age. The 4th Industrial Revolution. The age of AI. Reimagining every part of industry. Across the continent,  industrial AI is taking hold. From design to engineering. You're blazing new trails toward  understanding and reinvention. You brought the physical world into the virtual. To plan and optimize The world's modern factories. You're building the next frontier. Where everything that moves is robotic. Every car an intelligent autonomous agent. And a new collaborative workforce to  help close the global labor shortage gap. Developers across the continent  are building every type of robot. Teaching them new skills. In digital twin worlds and robot gyms. Preparing them to work alongside us. In our factories. Warehouses The operating room. And at home. The 4th industrial revolution is here. Right where the first began.What do you think? I love that video.  You made it. That's so great. You made it. Well, we're working on industrial AI with one  company after another. This is a BMW. Building  their next generation factory in Omniverse. This isâ€¦I don't know how to say it. Can somebody  teach me? Sounds good. Exactly. That's exactly  right. Good job. Good job. That's exactly right. They're building, of course, their plants,  digital twins and Omniverse is key. Their  digital twin for warehouse logistics. This is Mercedes Benz and their digital twins  of their factories built in Omniverse. This is  Schaeffer and their digital twin of  their warehouse built in Omniverse. This is your train station here in France  building a digital twin of their train stations in  Omniverse. And this is Toyota building a digital  twin of their warehouse in Omniverse. And when,  when you build these warehouses and these  factories and Omniverse, then you could design it,  you can plan it, you can change it. In green-field itâ€™s wonderful,  in brown-field it's wonderful. You could simulate  its effectiveness before you go and physically  lift and move things around to discover it wasn't  optimal. And so the ability to do everything  digitally in a digital twin is incredible. But the question is why does the digital twin have  to be photoreal and why does it have to obey the  laws of physics? The reason for that is because  we wanted ultimately to be a digital twin where a  robot could learn how to operate as a robot. And  robots rely on photons for their perception system  and those photons are generated through Omniverse. And a robot needs to interact with the physical  world so that it could know whether it's doing  the right things and learn how to do it  properly. And so these digital twins have  to look real and behave realistically. Okay,  so that's the reason why Omniverse was built. This is fantastic. This is a fusion reactor  digital twin. Incredibly complicated piece of  instrument as you know, and without AI the next  generation fusion reactor would not be possible. We're announcing today that we are going to  build the world's first industrial AI cloud  here in Europe. Yep. These industrial AI clouds are, yes, a whole  lot of computers in the cloud. However,  the requirements, its performance, its safety  requirements fundamentally different. And so I'm  going to tell you a lot more about it on Friday.  I'm only teasing you part of the story today,  but this industrial cloud will be  used for design and simulation. Virtual wind tunnels that you just walk  into. Virtual wind tunnels you just move  a car into and you see it behave. Open  doors, open windows, change the design. All completely in real time. Design in real  time, simulate in a digital wind tunnel,  digital twin of a wind tunnel in real time,  build it in a factory of a digital factory  twin in real time. All of this, and the robots  learn how to be great robots and build the  robots of our future, self driving cars and such. We already have a tremendous ecosystem here. We've  been here, as you know, for a very long time.  NVIDIA is 33 years old. The first time we came  to Europe was during the time when workstations  and the digitalization of products, CAD, the CAD  revolution started. We were here during the CAE  revolution and now the digital twin revolution. Some $2 trillion of ecosystem here in  Europe that we partner with and that have  the privilege of supporting. What comes out  of that is a new revolution that's happening. As you know, everything that moves will be  robotics, everything that moves will be AI-driven,  and the car is the most obvious next one. NVIDIA builds the AI supercomputers  to train the model. The AI supercomputer  for Omniverse digital twins. We also build  the AI supercomputers for the robot itself. In every single case, whether it's in the cloud  for Omniverse or in the car, we offer the entire  stack, the computer itself, the operating  system that runs on top of this computer,  which is different in every single case. This computer, high-speed, sensor-rich,  must be functionally safe. In no  circumstance could it fail completely. And so the safety requirements are incredibly  high. And now we have an incredible model that  sits on top of it. This model that sits on top  of it is a transformer model. It's a reasoning  model. It takes sensor in, you tell it what  you want it to do, and it will drive you there. Takes pixels in and it generates path  plans output. So it's a generative AI  model based on transformers. Incredible technology NVIDIAâ€™s AI team, AV team, is incredible. This is the only team that I know that has  won end-to-end self-driving car  challenge at CVPR two years in a  row. And so they're the winner again this year.  Let's take a look at the video. Yep, thank you. video Let's take a look at what they do.  Like any driver, autonomous vehicles  operate in a world full of unpredictable  and potentially safety critical scenarios. NVIDIA Drive built on the Halos safety system. Lets developers build safe autonomous  vehicles with diverse software stacks  and sensors and redundant computers. It starts with training. Safe AVs need massive  amounts of diverse data to be able to address  edge cases, but real world data is limited. Developers use NVIDIA Omniverse and  Cosmos to reconstruct the real world  and generate realistic synthetic training  data to bring diversity to the AV model. The model can perceive and  reason about its environment. Predict future outcomes. And generate a motion plan. And for decision making diversity, an independent  classical stack runs in parallel. Guardrails monitors safe performance. And in cases of anomalies, calls the  arbitrator to make an emergency stop. Further diversity and redundancy are built  into the sensor and compute architecture. Each sensor connects to redundant computers,  so even if a sensor or computer fails,  the vehicle stays safe and operational. And in the event of a critical failure,  the system can execute a minimum risk  maneuver like pulling over to the shoulder. Safety is foundational to autonomous driving. NVIDIA Drive lets developers worldwide  integrate Halos into their own products  to build the next generation of safe AVs.A billion cars on the road, 10,000 miles  a year on average, ten trillion miles. The future of autonomous  driving is obviously gigantic. And it's going to be driven,  it's going to be powered by AI. This is, this is the next gigantic opportunity. And we're working with enormous companies and  really fantastic companies around  the world to make this possible. At the core of everything we do here  with AV is safety and we're really,  really proud of our Halos system. It starts with the architecture of the  chip and then the chip design and the systems  design, the operating systems, the AI models,  the methodology of developing the software, the  way we test it, everything from the way we train  the models, the data we provide for the models,  all the way to the way we evaluate the models.  NVIDIAâ€™s Halos system and our AV safety team  and capabilities are absolutely world-renowned.  This computer was the first one to be  software-defined, the world's first software  defined completely 100% software-defined, AI  driven stack for AVs. We've been at this now for  coming up on ten years. And so this capability  is world-renowned and I'm really proud of it. The same thing that's happening for  cars is happening for a new industry. As I mentioned earlier, if you  can generate video from prompts. AI can perceive, it can reason. It can generate videos and words  and images. And just now with cars,  the path, the steering wheel path. Why can't it also generate locomotion  abilities and articulation abilities?  So that fundamental ability for AI to  revolutionize one of the hardest robotics  problems is around the corner. Humanoid  robots are going to be a thing. We now  know how to build these things, train  these things, and operate these things. Human robotics is going to potentially  be one of the largest industries ever. And it requires companies who  know how to manufacture things. Manufacture things of extraordinary capabilities.  This speaks of the European countries. So much  of the world's industries are based here. I  think this is going to be a giant opportunity. Well, let's say it's a billion  robots around the world. The idea that there'd be a billion robots is a  very sensible thing. Now why hasn't it happened? Well, the reason for that is simple. Today's robots are too hard to program. Only the largest companies can afford  to install a robot, get it, to teach it,  program it to do exactly the right things. Keep it sufficiently surrounded so that it's safe. That's the reason why the world's largest car  companies have robots. They're large enough.  The work is sufficiently repetitive. The industry is at a sufficient scale  that you could deploy robots into those  factories. Almost everybody who is a middle,  or small and medium companies, or mom and  pop restaurants or stores or warehouses, it's  impossible to have that programming capability. Until now. We're going to give you essentially  robots where you could teach them. They'll  learn from you. Just as we were talking about  Agentic AI, we now have humanoid AI that can learn  from your teaching using toolkits that are very  consistent with the NeMo tools I spoke about. NVIDIA here as well is built in a three-layer  stack. We build the computer, the Thor  computer dev kit. looks a little bit like this. This is a robotic computer, completely  self-contained dev kit sits on your desk. These are all the sensors and inside  is a little supercomputer Thor chip. Really, really incredible. And these. Yep.  Yeah. I could imagine getting one of these  inserted like that. Okay, thank you. So that's the Thor processor. On top  is an operating system designed for robotics.  And on top of that, transformer models that  take sensor data and instructions and transforms  them and generates paths and motor controls for  arm articulation, finger articulation,  and of course your legs articulation. Now the big challenge of human robotics is the  amount of data necessary to train. It is very,  very hard to get. And so the question is, how do  you do that? Well, the way you solve that problem  is to back in Omniverse, a digital twin world  that obeys the laws of physics. And this is an  incredible piece of work that we're doing. Don't do it. Don't  Oh. My fault Okay, these are robots. We developed computers to train them, computers  to simulate them and the computer that goes  inside them. There's a whole bunch of human  robotics companies being built around the world.  They all see the great opportunity to  revolutionize this new device if you will. And  the progress is going incredibly fast. And the  way that they all learn is they learn in a virtual  world. and this virtual world has to obey the  laws of physics. And recently we announced a big  partnership with Disney Research and DeepMind,  and we're going to work together to create the  world's most sophisticated physics simulation. And I'm just trying to figure out at this point  how to go to that slide. Teach me who's with me.  This is what happens when you only rehearse once. Okay, so this this. Incredible system This  incredible system is where an AI learns how to  be an AI. Let me show it to you. videoWe have a special guest. Your name is Grek. Are you a petite garson or petite belle? Okay. Grek is a little girl. Now look at this. Grek learned  how to walk inside Omniverse. Obeying the laws of physics. But inside Omniverse, we created  hundreds of thousands of scenarios. Then finally, when Grek learned how  to operate and walk and manipulate in those  environments on sand and on, you know, on gravel,  slippery floors, on concrete, on carpet. Then when it comes, when Greg comes into  the physical world, the physical world  is just the 100,001 version of the world.  And so you learn how to walk the  virtual world and look at you now. Can you, can you jump? Wow. Can you dance? Well, I think, I think, um. I just want to  let you know I am the keynote presenter. So I need you, I need you to behave. I  need you to behave for a few seconds. I need you to behave for a few  seconds. Could you sit? Sit. Hey, you know what we should do?  Let's take a picture of everybody. Yeah. Bam. bam. Would you like to come home with me?  Would you like to come home with me? I got. Yeah, I know. Yeah, I have pets. They  would like to have you as a pet. No? No. You're so smart. You're  so smart. Well. Incredible right? Grek you are the world's best robot  and someday we'll all have one like  you and they'll follow us around. But if I need a glass of whiskey, you're going  to have to go tell somebody else to go get me a  glass of whiskey because you have no arms. Yeah. You're so cute. Okay little girl,  you stay here for a second. Let's wrap up. Alright. It's very clear. It's very clear an  industrial revolution has started. The  next, the next wave of AI has started. Grek is a perfect example of what's possible  now with robotics. The technology necessary to  teach a robot. To manipulate to simulate. And of course the manifestation of an  incredible robot is now right in front of us. We have physical robots and we have information  robots. We call them agents. So the next wave of  AI has started. It's going to require inference  workloads to explode, it's basically going to  go exponential. The number of people that are  using inference has gone from 8 million to 800  million, a hundred times in just a couple of  years. The number, the amount of prompts that,  the tokens generated, as I mentioned earlier,  from a few hundred tokens to thousands of tokens.  And of course we use AI even more than ever today. So we need a special computer designed  for thinking, designed for reasoning. And  that's what Blackwell is, a thinking machine. These Blackwells will go into new types of  datacenters, essentially AI factories designed  for one thing and one thing only. And these AI  factories are going to generate tokens, and these  tokens are going to become your food, little Grek. I know, I know. And what's really incredible,  I'm so happy to see that Europe is going all  in on AI. The amount of AI infrastructure  being built here will increase by an order  of magnitude in the next couple of years. I want to thank all of you for your  partnership. Have a great VivaTech. Thank you. Say bye bye. Say bye bye. Take a bunch of  pictures. Take a bunch of pictures. Take a  bunch of pictures. Yeah.